{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP N°1 : Algèbre - Remise à niveau - Question 4\n",
    "## Romain DOMART\n",
    "### 09/10/2018\n",
    "\n",
    "L'objectif de cette question est de reproduire les valeurs trouvées dans les tableaux 3.2 et 3.3 disponibles dans *Hastie, Trevor, Tibshirani, Robert and Friedman, Jerome. The Elements of Statistical Learning. New York, NY, USA: Springer New York Inc., 2001.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(precision=3)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_nones(length, list_):\n",
    "    \"\"\"\n",
    "    Appends Nones to list to get length of list equal to `length`.\n",
    "    If list is too long raise AttributeError\n",
    "    \"\"\"\n",
    "    diff_len = length - len(list_)\n",
    "    if diff_len < 0:\n",
    "        raise AttributeError('Length error list is too long.')\n",
    "    return list_ + [None] * diff_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romaindomart/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data\",delimiter = '\\t+',index_col=0)\n",
    "resultats = pd.DataFrame(index=[\"Intercept\",\"lcavol\",\"lweight\",\"age\",\"lbph\",\"svi\",\"lcp\",\"gleason\",\"pgg45\"])\n",
    "zScore = pd.DataFrame(index=[\"Intercept\",\"lcavol\",\"lweight\",\"age\",\"lbph\",\"svi\",\"lcp\",\"gleason\",\"pgg45\"])\n",
    "error = pd.DataFrame(index = [\"MSE\",\"Std Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse exploratoire des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() #Permet d'afficher si les données ont été correctement importées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() # PPermet d'avoir des premieres informations sur le jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude des corrélations entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,5))\n",
    "sns.heatmap(data.corr(),cmap=\"viridis_r\",annot=True)\n",
    "plt.title(\"Heatmap of correlation between variables\")\n",
    "f.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion de l'analyse exploratoire\n",
    "\n",
    "On peut remarquer plusieurs choses : \n",
    "* la variables svi est un variable qualitative prenant deux valeurs $(0,1)$\n",
    "* la variable gleason ne prend que 4 valeurs $(6,7,8,9)$. \n",
    "* il y a une correlation entre les variables **lcavol** et **lpsa** ainsi qu'entre les variables **lcp** et **lpsa**. Or les variables **lcavol** et **lcp** sont elles aussi corrélées entre elles. Ainsi on peut tout de suite savoir que pour un modèle de regression prenant la variable **lcavol** en paramètre, l'ajout supplémentaire de **lcp** n'apportera que peu de nouvelles informations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation du problème de regression\n",
    "\n",
    "Soit $n=93$, le nombre d'observations et $p=8$ le nombre de variables : \n",
    "\n",
    "On définit \n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\mathbf{X} \\in \\mathcal{M}_{n,p} & \\mathbf{y} \\in \\mathcal{M}_{n,1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"lpsa\",\"train\"],axis=1).values\n",
    "y = data[\"lpsa\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrage - Réduction de l'ensemble des valeurs Cette étape doit être omise dans une démonstration rigoureuse. On y a recours pour retrouver les résultats du livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X=scaler.fit(X).transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des sets d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[data[\"train\"]==\"T\"]\n",
    "X_test= X[data[\"train\"]==\"F\"]\n",
    "y_train= y[data[\"train\"]==\"T\"]\n",
    "y_test = y[data[\"train\"]==\"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_test_mean = y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares\n",
    "On définit la fonction $f$ telle que \n",
    "\n",
    "\n",
    "$$f:\n",
    "\\left|\n",
    "  \\begin{array}{rcl}\n",
    "    {M}_{n,p} & \\longrightarrow & {M}_{n,1} \\\\\n",
    "    \\mathbf{X} & \\longmapsto &   \\mathbf{X}\\beta + \\beta_{0} \\\\\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "avec $\\beta_{0}^{\\ast}$ et $\\beta^{\\ast}$ les paramètres *réels* du modèle tel que $\\mathbf{y}=f\\left(\\mathbf{X},\\beta_{0}^{\\ast},\\beta^{\\ast}\\right)$.\n",
    "\n",
    "On définit ensuite $\\hat{\\mathbf{y}}$, $\\hat{\\beta}_{0}$ et $\\hat{\\beta}$ les prédictions et paramètres *estimés* par le modèle de régression tels que $\\hat{\\mathbf{y}} = f\\left(\\mathbf{X},\\hat{\\beta}_{0}, \\hat{\\beta}\\right)$.\n",
    "\n",
    "Enfin on définit $\\beta_{0}$ et $\\beta$ des paramètres *libres*.\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}\n",
    "&=\\text{arg}\\min_{\\beta} \\left( \\sum_{i=1}^{n}\\left(y_{i}-f\\left(x_{i}\\right)\\right)^{2}\\right) \\\\\n",
    "&=\\text{arg}\\min_{\\beta} \\left( \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\sum_{j=1}^{p}\\left(x_{i,j}\\beta_{j}\\right)\\right)^{2} \\right) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "On définit :\n",
    "\\begin{align}\n",
    "\\mathbf{X}_{a} =\n",
    "\\begin{bmatrix} \n",
    "1& x_{1,1} &  \\dots & x_{1,p} \\\\\n",
    "\\vdots &\\vdots & \\ddots & \\vdots \\\\\n",
    "1&x_{1,p} &    \\dots    & x_{n,p} \n",
    "    \\end{bmatrix} & \n",
    "    & \n",
    "    \\mathbf{\\beta}_{a} = \\begin{bmatrix} \n",
    "\\beta_{0}\\\\\n",
    "\\beta_{1}\\\\\n",
    "\\vdots \\\\\n",
    " \\beta_{p} \n",
    "    \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "On obtient $\\beta$ de la forme : \n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}&=\\text{arg}\\min_{\\beta} \\left( \\|\\mathbf{y}-\\mathbf{X_{a}\\beta_{a}\\|}^{2} \\right) \n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la regression des moindres carrés - Solution analytique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = X_train.shape\n",
    "d = np.ones((n,1))\n",
    "#Création de Xa\n",
    "Xa = np.concatenate((d,X_train), axis = 1) \n",
    "#Résolution du problème des moindres carrés\n",
    "beta_ls = np.linalg.solve(np.matmul(Xa.T,Xa),np.matmul(Xa.T,y_train))\n",
    "print('Beta Least Square from analytics: \\n', beta_ls)\n",
    "\n",
    "#Prédictions de y\n",
    "n,p = X_test.shape\n",
    "d = np.ones((n,1))\n",
    "Xa_test = np.concatenate((d,X_test), axis = 1)\n",
    "predictions_analytics_ls = np.matmul(Xa_test,beta_ls)\n",
    "print('\\n\\nPredictions from analytics: \\n', predictions_analytics_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Optionnel - Calcul de la regression des moindres carrés - Solution du package sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "ls = LinearRegression()\n",
    "ls.fit(X_train,y_train)\n",
    "print('Beta Least Square from package () : \\n',ls.intercept_, ls.coef_)\n",
    "predictions_package_ls = ls.predict(X_test)\n",
    "print('\\n\\nPredictions from package: \\n', predictions_package_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la regression des moindres carrés - Calcul des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE analytics:' , metrics.mean_squared_error(y_test,predictions_analytics_ls))\n",
    "print('MSE package:' , metrics.mean_squared_error(y_test,predictions_package_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Standard error analytics: ', np.sqrt(sum((y_test-predictions_analytics_ls)**2)/y_test.shape[0]))\n",
    "print ('Standard error package: ', np.sqrt(sum((y_test-predictions_package_ls)**2)/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats[\"Least Square\"] = beta_ls\n",
    "error[\"Least Square\"] = [metrics.mean_squared_error(y_test,predictions_analytics_ls),np.sqrt(sum((y_test-predictions_analytics_ls)**2)/y_test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul du meilleur subset - Z score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappelons tout d'abord l'expression générale du z-score\n",
    "\\begin{align}\n",
    "    z &= \\frac{x-\\bar{x}}{\\sqrt{\\text{Var}(x)}}\n",
    "\\end{align}\n",
    "Avec $\\bar{x}$ la moyenne de $x$ et $\\sqrt{\\text{Var}(x)}$ l'écart-type de x.\n",
    "\n",
    "Notons l'expression du z-score dans le cas de $\\hat{\\beta_{a}}$\n",
    "\\begin{align}\n",
    "    z &= \\frac{\\hat{\\beta_{a}}-\\bar{\\hat{\\beta_{a}}}}{\\sqrt{\\text{Var}(\\hat\\beta_{a})}}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{E}\\left(\\hat{\\beta_{a}}\\right) &= \\mathbf{E}\\left(\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y}\\right) \\\\\n",
    "&= \\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\mathbf{E}\\left(\\mathbf{y}\\right) \\\\\n",
    "&= \\left(\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)\\beta_{a}^{\\ast}+\\mathbf{E}\\left(\\mathbf{\\epsilon}\\right)\\\\\n",
    "&= \\mathbf{I}\\beta_{a}^{\\ast}\\\\\n",
    "&= \\beta_{a}^{\\ast}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Et \n",
    "\\begin{align}\n",
    "    \\text{Var}\\left(\\hat{\\beta_{a}}\\right) &= \\text{Var}\\left(\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\mathbf{y}\\right) \\\\\n",
    "    &= \\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\text{Var}\\left(\\mathbf{y}\\right)\\mathbf{X_{a}}\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\\\\n",
    "    &= \\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X}^{T}\\text{Var}\\left(\\mathbf{X_{a}}\\beta_{a}^{\\ast}+\\mathbf{\\epsilon}\\right)\\mathbf{X_{a}}\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\\\\n",
    "    &= \\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\text{Var}\\left(\\mathbf{\\epsilon}\\right)\\mathbf{X_{a}}\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1} \\\\\n",
    "    &= \\sigma^2\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1} \\\\\n",
    "    &= \\sigma^2\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Pour tester l'hypothèse qu'un certain coefficient ${\\beta_{a_j}^{\\ast}} = 0$ pour $j=1 \\cdot p$, on introduit donc le $Z-score$ tel que:\n",
    "\\begin{align}\n",
    "    z_j &= \\frac{\\hat{\\beta_{a_{j}}}}{\\hat{\\sigma}\\sqrt{v_j}} \n",
    "\\end{align}\n",
    "\n",
    "avec $v_j$ le $j^e$ élément de la diagonale de $\\left(\\mathbf{X_{a}}^{T}\\mathbf{X_{a}}\\right)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = X_train.shape\n",
    "V_ls = np.matmul(Xa.T,Xa) # Calcul de V\n",
    "V_ls_inv = np.linalg.inv(V_ls) # Inverse de V\n",
    "v = np.diagonal(V_ls_inv) # Diagnonale de V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul de sigma\n",
    "sigma = 0\n",
    "for i in range (n):\n",
    "    sigma = sigma+(y_train[i]-np.matmul(Xa,beta_ls)[i])**2\n",
    "sigma = (1/(n-p-1))*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des z\n",
    "z=[]\n",
    "for i in range(beta_ls.shape[0]):\n",
    "    zi = beta_ls[i]/np.sqrt(sigma*v[i])\n",
    "    z.append(zi)\n",
    "zScore[\"Coefficient\"]=beta_ls\n",
    "zScore[\"Std Error\"] = sigma*v\n",
    "zScore[\"Z-value\"]=z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Tableau 3.2\\n',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les Z-values pour Intercept, lcavol et lweight sont les plus élevés. Ce sont les variables pour lesquels l'hypothèse ${\\beta_{a_j}^{\\ast}} = 0$ peut être rejetée avec le plus de certitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Optionnel - Calcul du meilleur subset - Suite*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le calcul d'une regression sur l'ensemble des variables n'est pas avantageux dans le sens où l'addition de variables supplémentaires au modèle ne peut apporter que très peu d'informations supplémentaires. Il nous faut ainsi sélectionner le meilleur compromis entre le nombre de variables et le taux d'erreur de la regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Recherche exhaustive des subsets*\n",
    "\n",
    "Ici nous allons effectuer une recherche exhaustive sur l'ensemble des combinaisons de variables possibles pour le calcul de la regression puis calculer deux indicateurs : l'AIC et le BIC afin de déterminer le tuple de variables à considérer dans notre regresssion.\n",
    "\n",
    "Pour cela, et comme ce n'est pas le sujet du TP, nous allons utiliser le package statsmodel pour effectuer la régression des moindres carrés et determiner directement ces deux indicateurs avant de réefectuer le calcul de la regression avec le subset choisi par l'énoncé de manière analytique\n",
    "\n",
    "Note : Le code python utilisé ci-dessous n'est pas optimisé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul exhaustif des combinaisons de variables\n",
    "\n",
    "from itertools import chain, combinations\n",
    "l=list(chain(*map(lambda x: combinations(range(8),x),range(0,len(range(8))+1))))\n",
    "l = l[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des BIC / AIC avec le package statsmodel\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "listofaic = []\n",
    "listofbic=[]\n",
    "for x in l : \n",
    "    regr = OLS(y_train,add_constant(X_train[:,x])).fit()\n",
    "    listofaic.append(regr.aic)\n",
    "    listofbic.append(regr.bic)\n",
    "\n",
    "\n",
    "daic = pd.DataFrame([l,listofaic]).T.sort_values(by=[1]).reset_index().drop(\"index\",axis=1)\n",
    "dbic =pd.DataFrame([l,listofbic]).T.sort_values(by=[1]).reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Calculs des meilleurs subsets*\n",
    "On peut ainsi déterminer les meilleurs subsets sur lesquels effectuer la regression des moindres carrés. \n",
    "\n",
    "*0 = lcavol \\[...\\] 7 = pgg45*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Critère BIC \\n\", dbic.head(5))\n",
    "print (\"Critère AIC \\n\",daic.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Critère BIC pour les tuples de taille 2\\n\",dbic[dbic[0].str.len()==3].head(5))\n",
    "print(\"Critère AIC pour les tuples de taille 2\\n\",daic[daic[0].str.len()==3].head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve les résultats obtenus avec le calcul des $Z-scores$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Subset\n",
    "### Calcul de la regression des moindres carrés pour le meilleur subset $(0,1)$ - Solution analytique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[data[\"train\"]==\"T\"][:,[0,1]]\n",
    "X_test= X[data[\"train\"]==\"F\"][:,[0,1]]\n",
    "y_train= y[data[\"train\"]==\"T\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = X_train.shape\n",
    "d = np.ones((n,1))\n",
    "Xa = np.concatenate((d,X_train), axis = 1)\n",
    "beta_ls = np.linalg.solve(np.matmul(Xa.T,Xa),np.matmul(Xa.T,y_train)) #Résolution du problème\n",
    "print('Beta Least Square from analytics: \\n', beta_ls)\n",
    "n,p = X_test.shape\n",
    "d = np.ones((n,1))\n",
    "Xa_test = np.concatenate((d,X_test), axis = 1)\n",
    "predictions_analytics_ls = np.matmul(Xa_test,beta_ls)\n",
    "print('\\n\\nPredictions from analytics: \\n', predictions_analytics_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE analytics:' , metrics.mean_squared_error(y_test,predictions_analytics_ls))\n",
    "print ('Standard error analytics: ', np.sqrt(sum((y_test-predictions_analytics_ls)**2)/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats[\"Best Subset\"] = append_nones(resultats.shape[0],list(beta_ls))\n",
    "error[\"Best Subset\"] = [metrics.mean_squared_error(y_test,predictions_analytics_ls),np.sqrt(sum((y_test-predictions_analytics_ls)**2)/y_test.shape[0])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f:\n",
    "\\left|\n",
    "  \\begin{array}{rcl}\n",
    "    {M}_{n,p} & \\longrightarrow & {M}_{n,1} \\\\\n",
    "    X & \\longmapsto &  \\mathbf{X}\\beta + \\beta_{0} +\\lambda\\beta \\\\\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "On définit $\\beta_{0}^{\\ast}$ et $\\beta^{\\ast}$ les paramètres *réels* du modèle tel que $\\mathbf{y}=f\\left(\\mathbf{X},\\beta_{0}^{\\ast},\\beta^{\\ast}\\right)$.\n",
    "\n",
    "On définit ensuite $\\hat{\\mathbf{y}}$, $\\hat{\\beta}_{0}$ et $\\hat{\\beta}$ les prédictions et paramètres *estimés* par le modèle de régression tels que $\\hat{\\mathbf{y}} = f\\left(\\mathbf{X},\\hat{\\beta}_{0}, \\hat{\\beta}\\right)$.\n",
    "\n",
    "Enfin on définit $\\beta_{0}$ et $\\beta$ des paramètres *libres*.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}&=\\text{arg}\\min_{\\beta} \\left( \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\sum_{j=1}^{p}\\left(x_{i,j}\\beta_{j}\\right)\\right)^{2} + \\lambda\\sum_{j=1}^{p}\\beta_{j}^{2}\\right) \n",
    "\\end{align}\n",
    "Avec $\\lambda\\geq 0$ fixé\n",
    "Centrons maintenant la matrice $\\mathbf{X}$ tel que $\\mathbf{X_c} = \\mathbf{X}-\\mathbf{\\bar{X}}$. Ainsi on a :\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\beta}&=\\text{arg}\\min_{\\beta} \\left( \\sum_{i=1}^{n}\\left(y_{i}-\\sum_{j=1}^{p}\\left(x_{c_{i,j}}\\beta_{j}\\right)\\right)^{2} + \\lambda\\sum_{j=1}^{p}\\beta_{j}^{2}\\right) \\\\\n",
    "&=\\text{arg}\\min_{\\beta} \\left( \\|{\\mathbf{y}-\\mathbf{X_c\\beta}\\|}^{2} + \\|{\\lambda\\beta}\\|\\right) \n",
    "\\end{align}\n",
    "\n",
    "On trouve $\\beta$ de la forme : \n",
    "\n",
    "\\begin{align}\n",
    "    \\beta &= \\left(\\mathbf{X_{c}}^{T}\\mathbf{X_{c}} - \\lambda\\mathbf{I}\\right)^{-1}\\mathbf{X_{c}}^{T}\\mathbf{y}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Il faut tout d'abord centrer nos données d'apprentissage et de test. \n",
    "\n",
    "Ici, afin de retrouver les valeurs du tableau à reproduire, on centre aussi les valeurs de $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[data[\"train\"]==\"T\"]\n",
    "X_test= X[data[\"train\"]==\"F\"]\n",
    "y_train= y[data[\"train\"]==\"T\"]\n",
    "y_test = y[data[\"train\"]==\"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_std=False)\n",
    "X_train=scaler.fit(X_train).transform(X_train)\n",
    "X_test=scaler.fit(X_test).transform(X_test)\n",
    "y_train = y_train-y_train_mean\n",
    "y_test = y_test - y_test_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du $\\lambda$ \n",
    "\n",
    "On définit tout d'abord la décomposition singulière de $\\mathbf{X}$ telle que : \n",
    "\\begin{align}\n",
    "\\mathbf{X}_{c} \n",
    "&= \\mathbf{U}\\mathbf{D}\\mathbf{V}^{T}\n",
    "\\end{align}\n",
    "\n",
    "Avec : \n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\mathbf{D} \\in \\mathcal{M}_{n,p} & \\mathbf{U} \\in \\mathcal{M}_{n,n} & \\mathbf{V} \\in \\mathcal{M}_{p,p}\n",
    "\\end{array}\n",
    "$$\n",
    "L'énoncé nous indique : \n",
    "\n",
    "\\begin{align}\n",
    "df\\left(\\lambda\\right) &= \\text{tr}\\left(\\mathbf{X_{c}}^{T}\\mathbf{X_{c}} - \\lambda\\mathbf{I}\\right)^{-1}\\mathbf{X_{c}}^{T} \\\\\n",
    "&= \\sum_{j=1}^{p}\\left(\\frac{d_{j}^{2}}{d_{j}^{2}+\\lambda}\\right)\\\\\n",
    "&= 5  \n",
    "\\end{align}\n",
    "\n",
    "Avec $d_{1\\dots p}$ les valeurs portées par la diagonale de $\\mathbf{D}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000001\n",
      "         Iterations: 34\n",
      "         Function evaluations: 68\n",
      "Valeur de lambda telle que df(lambda)=5 : [24.249]\n"
     ]
    }
   ],
   "source": [
    "#Calcul de lambda avec le module scipy. On determine le minimum de la fonction df.\n",
    "\n",
    "import scipy\n",
    "\n",
    "U,d,V = scipy.linalg.svd(X_train)\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin\n",
    "import math\n",
    "\n",
    "def df(x):\n",
    "    df=0\n",
    "    for i in range(d.shape[0]):\n",
    "        df=df+(d[i]*d[i])/(d[i]*d[i]+x)\n",
    "    return abs(df-5)   \n",
    "array = np.array([0,df(0)])\n",
    "lamb = fmin(df,0)\n",
    "\n",
    "print('Valeur de lambda telle que df(lambda)=5 :', lamb)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Calcul manuel et non optimisé de lambda\n",
    "import scipy\n",
    "U,d,V = scipy.linalg.svd(X_train) # Décomposition en valeur singulière de X\n",
    "dfs = [] # On va stocker tous les abs(df(lambda)-5) dans une liste que l'on triera par la suite. \n",
    "#Ce n'est pas une solution très optimisée. Un algorithme de calcul du minimum (df(lambda)-5) \"à la volée\" aurait été préférable ici.\n",
    "for alpha_test in np.arange(0,100,0.00001):\n",
    "    df=0\n",
    "    for i in range(d.shape[0]):\n",
    "        df=df+(d[i]*d[i])/(d[i]*d[i]+alpha_test)\n",
    "    dfs.append(abs(df-5))\n",
    "lamb = np.arange(0,100,0.00001)[dfs.index(min(dfs))] #On  repere l'indice du minimum et l'on retrouve lambda.\n",
    "print('Valeur de Lambda : ',lamb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la regression Ridge - Solution analytique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = X_test.shape\n",
    "I = np.identity(p)\n",
    "Xtemp = np.matmul(X_train.T,X_train)\n",
    "Xtemp = np.add(Xtemp,lamb*I)\n",
    "beta_r = np.linalg.solve(Xtemp,np.matmul(X_train.T,y_train))\n",
    "\n",
    "\n",
    "print('Beta Ridge from analytics : \\n',y_train_mean, beta_r)\n",
    "predictions_analytics_r = y_test.mean() + np.matmul(X_test,beta_r)\n",
    "print('\\n\\nPredictions from analytics : \\n', predictions_analytics_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Optionnel - Calcul de la regression des moindres carrés - Solution du package sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=lamb)\n",
    "ridge.fit(X_train,y_train)\n",
    "print('Beta Ridge from package () : \\n',ridge.intercept_, ridge.coef_)\n",
    "predictions_package_r = ridge.predict(X_test)\n",
    "print('\\n\\nPredictions from package : \\n', predictions_package_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0.1,100,0.01)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgecv = RidgeCV(alphas = tuple(a))\n",
    "ridgecv.fit(X_train,y_train)\n",
    "print('\\n\\nBeta ridge from CV : ', ridgecv.intercept_, ridgecv.coef_)\n",
    "print('\\n\\nAlpha from CV : ', ridgecv.alpha_)\n",
    "predictions_crossval_r = ridgecv.predict(X_test)\n",
    "print('\\n\\nPredictions from CV : \\n', predictions_crossval_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE analytics:' , metrics.mean_squared_error(y_test,predictions_analytics_r))\n",
    "print('MSE package:' , metrics.mean_squared_error(y_test,predictions_package_r))\n",
    "print('MSE crossval:' , metrics.mean_squared_error(y_test,predictions_crossval_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Standard error analytics: ', np.sqrt(sum((y_test-predictions_analytics_r)**2)/y_test.shape[0]))\n",
    "print ('Standard error package: ', np.sqrt(sum((y_test-predictions_package_r)**2)/y_test.shape[0]))\n",
    "print ('Standard error crossval: ', np.sqrt(sum((y_test-predictions_crossval_r)**2)/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=beta_r.tolist()\n",
    "b.insert(0,y_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats[\"Ridge\"]=b\n",
    "error[\"Ridge\"] = [metrics.mean_squared_error(y_test,predictions_analytics_r),np.sqrt(sum((y_test-predictions_analytics_r)**2)/y_test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau 3.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Intercept, lcavol, lweight, age, lbph, svi, lcp, gleason, pgg45]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tableau 3.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Intercept, lcavol, lweight, age, lbph, svi, lcp, gleason, pgg45]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std Error</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [MSE, Std Error]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Tableau 3.2')\n",
    "display(zScore)\n",
    "print('\\n\\nTableau 3.3')\n",
    "display(resultats)\n",
    "display(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
